Docker 위에 카프카 및 ELK를 구축해보자~~~

우분투를 무사히 설치했다면 이제 도커위에 카프카 및 ELK를 구축해보자 

일단 ELK를 우분투에 설치해서 전부 연동 시켜도 되지만 내 개인적인 생각으로는 도커위에 만드는게 관리하기도 더욱 편한것 같다. 근데 도커가 무엇일까?? 뭔데 자꾸 도커위에 올려야 한다고 하나 도커에 대해 설명해보겠다. 이건 내가 공부한것을 바탕으로 한 것이니 완전히 맞는것은 아니다. 

도커란??
1.	일단 도커의 강점은 돌고래가 아주 귀엽다 그래서 사용해보고 싶은 욕구가 뿜뿜한다.
2.	도커는 컨테이너라는 가상머신 비슷한 원리를 사용한다. 가상머신 위에 올려놓고 사용하기 때문에 적정량의 메모리를 분배할 수 있다. 
3.	Docker-compose 를 사용하면 내가 원하는 시스템을 한번에 구축해버릴 수 있다. 컴포즈 파일만 실행하면 내가 작성한 컴포즈파일을 기반으로 모든 시스템이 한번에 올라간다.
4.	Docker-swarm 을 사용하면 여러대의 컴퓨터를 하나의 시스템을 운영하는데 사용할 수 있다. 원래대로라면 컴퓨터 1대로 로그스태시,엘라스틱서치,카프카등 전부다 운영해야하지만 도커를 사용하면 여러대가 적당량의 일을 도맡아서 하는 유토피아를 실현할 수 있다. 

도커는 컨테이너라는 개념을 사용한다. 컨테이너는 가상머신을 말한다고 하면 조금 이해가 편할가???? 아무튼 컨테이너 안에 로그스태시를 넣을수도 있고 엘라스틱 서치를 넣을수도 있고 컨테이너 별로 따로 시스템을 구축할 수 있다. 심지어 이 컨테이너 안에는 우분투도 설치가 가능하다. 우분투위에 도커를 설치하고 도커위에 우분투를 설치하고 이런 무한루프도 가능할듯?(잘모름)

아무튼 우리가 해야할 것은 카프카,로그스태시,엘라스틱서치,키바나,주키퍼 << 이렇게 5개의 컨테이너를 만들것이다. 

첫번째로 도커를 설치해야한다. 
sudo apt update << 일단 리눅스 창에 요걸 입력해준다. 이건 그냥 실행전 몸풀기라고 생각하면 된다. 


sudo apt install apt-transport-https ca-certificates curl software-properties-common

위에 주소를 입력해줘서 도커 설치전 필요한 패키지를 설치한다~~~



curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable"


그이후 위에 줄을 입력해준다. 위에 명령어는 도커를 받아올 주소를 설정해주는것이다. 
우리가 도커를 설치하라고 하면 리눅스는 그게뭔데? 라고 반응한다. 왜냐면 받아올 주소가 없기때문 위에는 그 주소이다. 

sudo apt update

주소를 입력해줬으니 위에 명령어를 다시 입력한다. 위에 주소가 추가된걸 우리 설치프로그램에 업데이트 한것이다 이제 도커를 받아올 수 있다. ‘

apt-cache policy docker-ce

설치전 위에 명령어를 다시한번 입력후 설치해보자 위에거는 나도 잘 모름

sudo apt install docker-ce
위에 명령어를 실행시키면 도커가 설치된다 아마 100메가 정도이다. 
뒤에 CE가 붇는것은 도커는 회사용이 있고 개인용이 있다 개인용은 무료이다 CE는 개인용을 뜻하는것 (정확하지 않은데 맞을걸)

sudo systemctl status docker
자 위에 명령어를 입력해서 확인해보자 잘돌아가고 있다고 뜰것이다. 

도커위에 하나하나 올려줄거면 docker-compose를 설치할 필요가 없지만 우리는 한번에 올려버릴거라 dcoekr-compose가 필요하다. 설치해보자

sudo curl -L https://github.com/docker/compose/releases/download/1.25.0-rc2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

위에 명령어를 입력해준다. 근데 이게 뒤에보면 /usr/local/bin/docker-compose < 이렇게 되어 있는데 이 경로는 내 도커가 인식을 못했다. 그래서 나는 /usr/bin/docker-compose 	< 이렇게 해줬다. 위에걸로 해보고 안되면 나처럼 해보자 그래도 안되면 전화해라 이거는 경로가 완전히 다른건데 그걸 아는 방법은 글로 쓰기가 힘들다.


위에서 도커 컴포즈를 받았으면 
sudo chmod +x /usr/local/bin/docker-compose

이렇게 권한설정도 해준다. 위 설치에서 경로를 바꿔줫다면 경로도 다시 바꿔줘야겟쥬??

docker-compose --version

도커 버전을 확인해보자 1.25 일것이다. 



sudo usermod -aG docker $USER
설치후 위에 명령어도 입력하라는데 나는 안해도 잘됫다. 안해도됨












Docker-compose 파일 작성
도커를 잘 설치했으니 이제 컴포즈 파일을 만들어야한다. 나한텐 이 컴포즈 파일 만드는게 여간 쉽지 않았다. 그래도 잘 설명해보겠다. 이것은 인터넷에서도 자료가 잘 안나온다. 그러니 나의 자료를 잘 참고하도록 모르겠으면 전화해라 근데 전화해도 나도 모를수 있다. 

아래에 내가 만든 컴포즈 파일이다. Docker-compose 폴더를 하나 만들고 안에 들어가서 
vi Docker-compose.yml을 입력한다
그리고 아래 코드를 보자
version: "3"

services:
     elasticsearch:
       image: elasticsearch:7.6.1
       container_name: elasticsearch
       ports:
         - "9200:9200"
         - "9300:9300"
       environment:
          discovery.type: single-node
         - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
       volumes:
         

-./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml

     kibana:
       image: kibana:7.6.1
       container_name: kibana
       ports:
         - "5601:5601"
       environment:
        LS_JAVA_OPTS: "-Xmx512m -Xms512m"
       links:
         - elasticsearch
       volumes:
         - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml

    logstash:
      image: logstash:7.6.1
      container_name: logstash
      command: logstash -r -f /config-dir/logstash.conf
      ports:
        - "5044:5044"
        - "9600:9600"
      links:
        - elasticsearch
        - kafka
      volumes:
        - ./logstash/logstash.conf:/config-dir/logstash.conf
      environment:
        LS_JAVA_OPTS: "-Xmx512m -Xms512m"

    zookeeper:
      image: wurstmeister/zookeeper
      container_name: zookeeper
      ports:
        - "2181:2181"

    kafka:
      image: wurstmeister/kafka:2.12-2.0.1
      container_name: kafka
      ports:
        - "9092:9092"
      environment:
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.17.0.1:9092
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
        KAFKA_CREATE_TOPICS: "test-topic"
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
      depends_on:
        - zookeeper

    kafka-manager:
      image: sheepkiller/kafka-manager:latest
      environment:
        ZK_HOSTS: "zookeeper:2181"
      ports:
        - 9000:9000

다봣는가?? 처음에는 나보고 이걸 어떻게 만들라고 하는 생각이 절로난다 하지만 하나씩 실타래를 찾아가면 우리도 충분히 만들 수 있다. 

자 첫번째로 serivce를 입력했다 이건 내가 컨테이너 위에 올릴 서비스들을 넣어주는 란이다. 그러므로 우리는 여기에 엘라스틱서치, 로그스태시, 키바나,카프카, 주피터를 넣어줘야한다. 카프카 매니저도 있는데 이건 그냥 넣어져있는거 지워도 무방함

ElasticSearch를 입력해주고 : 그 이후 
image < 요기는 받아올 이미지 파일을 입력해줘야한다. Elasticsearch 7.6.1 버전의 이미지를 받아오란 얘기다. Docker hub 라는 홈페이지 에서 가져올 이미지를 골라준다. 도커에서 공식이미지를 지원하는데 웬만하면 그걸 받아보자 
Container Name < 요건 컨테이너 이름을 지정해 주는 란 
Port < 요것도 당연히 포트를 지정해 주는란 인터넷 주소란에 0.0.0.0:9200 < 이렇게 치면 엘라스틱서치가 등장하도록 설정해줄것이다. 
Environment < 이건 컨테이너 환경을 설정해준다.
environment:
        LS_JAVA_OPTS: "-Xmx512m -Xms512m" < 이거를 Xmx2048m 이런식으로 수정하면 메모리를 더 부가하는듯 테스트는 안해보았음

Volumes < 이건 내가 가지고 있는 파일로 컨테이너 안에 들어갈 파일을 추가한다.
-./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
위 코드의 경우 내 폴더 elastcsearch.yml 파일을 도커 엘라스틱서치 컨테이너 위에 elasticsearch.yml 파일로 넣겠다는 뜻임 

Link< 이건 서로 연결할 컨테이너 설정 카프카랑 로그스태시랑 이어줘야하고 로그스태시랑 엘라스틱 서치랑 이어줘야 하겟쥬??? 확실하지는 않으나 맞는듯

이것 말고도 더 있지만 우리가 원하는 바를 위해선 위의 코드들로 충분하다. 정말쉽쥬????

자그럼 위에 yml파일들을 만들어 줘야함 로그스태시,엘라스틱서치,키바나 이것들은 yml파일이 필요함 포트를 설정해주고 연결해줘야 한다. 하나하나 만들어 봅시다.





 


첫번째로 elasticsearch.yml을 만들어보자 엘라스틱 서치 폴더를 만들어주고 그안에 
Elasticsearch.yml 파일을 만들어주자

cluster.name: "docker-cluster"
network.host: 0.0.0.0
discovery.type: single-node
#xpack.monitoring.enabled: true
#xpack.monitoring.collection.enabled: true

위의 코드만 입력해주면 된다 간편하쥬?
Xpack은 사용하지 않을거기 때문에 주석처리해준다 #
네트워크 호스트는 오픈하기위해 0.0.0.0 으로 설정해줬다. 

다음은 키바나 
키바나도 똑같이 키바나 폴더를 만들어 주고 kibana.yml 을 만들어준다
server.name: "kibana"
server.host: "0.0.0.0"
elasticsearch.hosts: "http://elasticsearch:9200"
#xpack.reporting.csv.maxSizeBytes: 1048576000

위에 코드를 입력한다. 서버네임은 그냥 kibana로함 암캐나 해도됨
서버호스트 역시 0.0.0.0
키바나는 엘라스틱서치를 시각화하기 때문에 엘라스틱서치의 포트가 필요하다.
위에처럼 입력해주면 된당~


다음은 가장 중요한 로그스태시이다.
로그스태시는 yml이 아닌 conf 파일이다. 이 파일로 로그스태시가 가져올 포트와 로그를 전달해줄 포트를 설정해준다. 
똑같이 로그스태시 폴더를 만든후 logstash.conf 파일을 만들어 준다.
Vi logstash.conf 라고 치면 알아서 만들어진다.

input {
    stdin { codec => json }
    kafka{
        bootstrap_servers => "kafka:9092"
        topics => ["test-topic"]
        group_id => "group1"           
     }   
}         
         
filter {
json  
{            
source => "message"
   }
}   
    

output {
 stdout { codec => rubydebug }
    elasticsearch { 
        hosts => "elasticsearch:9200"
        index => "test"
     }

위의 코드를 입력해주면 된다. 인풋은 로그를 받을 주소를 입력해주면 된다. Json형식으로 받아서 코덱을 json으로 설정해주었다. 카프카에서 받아올거기 때문에 kafka:9092를 넣어줬고 토픽은 test-topic에 해당하는 토픽을 가져오도록 설정해주었다. 그룹아이디는 안넣어도 될걸?? 확인안해봄 이번에 보낸 데이터의 그룹아이디는 group1이라 위에처럼 입력해주었다.

우리가 json파일을 json파일에 해당하는 데이터만 들어오는것이 아니다 보면 이상한 로그들도 같이 온다. 필터는 이걸 걸러준다. 이제 슬슬 설명하기 어려워진다. 모르겠으면 전화해라 
우리가 보낸 json파일의 message에 해당하는 부분이 우리가 가져오고 싶은 값이었기에 위처럼 코드를 작성해 주었다. Message에 해당하는 부분만 가져온다.

아웃풋은 데이터를 보낼곳 우리는 엘라스틱서치로 보내 저장할거라 엘라스틱 서치로 설정해주었다. 저 코덱이 보기 좋다그래서 설정해주었고 호스트는 엘라스틱서치 포트 index는 test로 설정해주었다.인덱스는 원하는대로 설정해주면 된다. 

이제 설정파일들을 모두 만들어 주었다. 이제 모든 준비는 끝낫다 컴포즈파일을 올려보자
