{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밑에 나오는 모든 것들은 판다스 모듈을 불러와야한다.\n",
    "import pandas as pd \n",
    "\n",
    "#csv 파일읽기\n",
    "csvfile = pd.read_csv('/Path/test_csv_file.csv', index_col='column',False,1) \n",
    "# 인덱스를 컬럼으로 지정해주면 해당 컬럼이 인덱스가 된다. False는 아무것도 지정하지 않는다, \n",
    "#0으로 설정하면 첫번째 칼럼을 인덱스로 설정한다. 1로 설정하면 두번째 칼럼이 선택된다.\n",
    "\n",
    "# text 파일 불러오기 \n",
    "textfile = pd.read_csv(\"/Path/test_text_file.txt\", sep='|') # sep ='|' 추가해줘야함\n",
    "\n",
    "\n",
    "# csv 파일 로우 5개만 가져오기\n",
    "csvfilerow5 = pd.read_csv(\"/Path/test_csv_file.csv\", nrows =5) \n",
    "\n",
    "#json 파일 읽기\n",
    "jsondata = pd.read_json('test.json', orient='table') # 이걸로 제대로 안되면 orient='reocords' 활용해보자\n",
    "\n",
    "#df to json\n",
    "df.to_json(orient='records') # 데이터프레임을 제이슨 형태로 바꿔준다. \n",
    "\n",
    "#json 파일 읽어오기 import json 필요할듯\n",
    "with open('json file path or name') as json_file: # 이렇게 불러오면 전부가 메모리가 감당할 수 있는 범위에서 읽어온다고 함 정확하지 않음\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "\n",
    "    \n",
    "#--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas dataframe 합치기,나누기,칼럼선택등\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pd.concat(\n",
    "'''\n",
    "             axis=0,  # 0: 위+아래로 합치기, 1: 왼쪽+오른쪽으로 합치기\n",
    "\n",
    "             join='outer', # 'outer': 합집합(union), 'inner': 교집합(intersection)\n",
    "\n",
    "             join_axes=None, # axis=1 일 경우 특정 DataFrame의 index를 그대로 이용하려면 입력\n",
    "\n",
    "             ignore_index=False,  # False: 기존 index 유지, True: 기존 index 무시\n",
    "             keys=None, # 계층적 index 사용하려면 keys 튜플 입력\n",
    "\n",
    "             levels=None,\n",
    "\n",
    "             names=None, # index의 이름 부여하려면 names 튜플 입력\n",
    "\n",
    "             verify_integrity=False, # True: index 중복 확인\n",
    "             copy=True) # 복사)\n",
    "'''\n",
    "# 데이터 프레임 df에 df2를 아래로 붙이고 싶을때\n",
    "pd.concat([df,df2],axis=0)\n",
    "\n",
    "#데이터 프레임 df에 df2를 옆으로 붙이고 싶을때\n",
    "pd.concat([df,df2],axis=1)\n",
    "\n",
    "df['columns_name'] #해당 칼럼을 Series 형식으로 가져온다.\n",
    "\n",
    "df[0:5] # 첫번째부터 4번째 로우까지 가져온다 10:500 < 이렇게 할경우 10번째부터 499까지의 로우를 가져온다\n",
    "\n",
    "df.loc['로우':'로우','칼럼':'칼럼'] #loc의 경우 로우나 칼럼을 써줘야한다.\n",
    "\n",
    "df.loc[:,['해당칼럼','해당칼럼','해당칼럼']] # 해당 칼럼만 가져온다.\n",
    "\n",
    "df.iloc[로우int:로우int,칼럼int:칼럼int] # 행이랑 열을 int 형식으로 써줘야한다. 10:20,10:20 < 10~20까지의 로우 와 10번째부터 20번째까지의 칼럼\n",
    "\n",
    "df.iloc[:,[해당칼럼int,해당칼럼int,해당칼럼int]] # 해당 칼럼 번호에 해당하는것만 가져온다.\n",
    "\n",
    "df.info() # 칼럼마다 Null 값 존재 여부와 데이터타입 확인\n",
    "\n",
    "df_all.isnull().sum() # 칼럼별 결측치 총개수 확인\n",
    "\n",
    "df.fillna(0) #NaN을 0으로 채운다\n",
    "\n",
    "df.fillna(method='pad') # 결측치 바로 이전에 값으로 대체\n",
    "\n",
    "df.fillna(method='bfill') # 결측치 바로 다음 값으로 대체\n",
    "\n",
    "df.replace(to_replace=np.nan, value=int) # 결측치를 value값으로 대체\n",
    "\n",
    "df.dropna(axis=0,how='any') #결측이 있는 로우 삭제 how 옵션의 애니는 결측치가 있는 행 전부라는 뜻\n",
    "\n",
    "df.dropna(axis=1) #결측치가 있는 칼럼 삭제 \n",
    "\n",
    "df.dropna(subset=['해당칼럼','해당칼럼']) #해당 칼럼의 결측치 제거\n",
    "\n",
    "df.dropna(thresh=2) #로우의 결측치가 2개 이상이면 삭제해버린다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
